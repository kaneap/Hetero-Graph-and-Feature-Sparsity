{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import DBLP\n",
    "import torch.nn.functional as F\n",
    "from utils.graph_polluters import remove_features\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from modules.heteroGNN import HeteroGNN\n",
    "from utils.set_seed import set_seed\n",
    "from copy import deepcopy\n",
    "\n",
    "dataset = DBLP('./data/dblp', transform=T.Constant(node_types='conference'))\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  author={\n",
       "    x=[4057, 334],\n",
       "    y=[4057],\n",
       "    train_mask=[4057],\n",
       "    val_mask=[4057],\n",
       "    test_mask=[4057],\n",
       "  },\n",
       "  paper={ x=[14328, 4231] },\n",
       "  term={ x=[7723, 50] },\n",
       "  conference={\n",
       "    num_nodes=20,\n",
       "    x=[20, 1],\n",
       "  },\n",
       "  (author, to, paper)={ edge_index=[2, 19645] },\n",
       "  (paper, to, author)={ edge_index=[2, 19645] },\n",
       "  (paper, to, term)={ edge_index=[2, 85810] },\n",
       "  (paper, to, conference)={ edge_index=[2, 14328] },\n",
       "  (term, to, paper)={ edge_index=[2, 85810] },\n",
       "  (conference, to, paper)={ edge_index=[2, 14328] }\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.ModuleList()\n",
    "        self.decoder = torch.nn.ModuleList()\n",
    "\n",
    "        # Encoder\n",
    "        for i in range(len(hidden_dims)):\n",
    "            if i == 0:\n",
    "                self.encoder.append(torch.nn.Linear(input_dim, hidden_dims[i]))\n",
    "            else:\n",
    "                self.encoder.append(torch.nn.Linear(hidden_dims[i-1], hidden_dims[i]))\n",
    "            self.encoder.append(torch.nn.ReLU())\n",
    "        \n",
    "        # Decoder\n",
    "        for i in reversed(range(len(hidden_dims))):\n",
    "            if i == 0:\n",
    "                self.encoder.append(torch.nn.Linear(hidden_dims[i], input_dim))\n",
    "                self.encoder.append(torch.nn.Sigmoid())\n",
    "            else:\n",
    "                self.encoder.append(torch.nn.Linear(hidden_dims[i], hidden_dims[i-1]))\n",
    "                self.encoder.append(torch.nn.ReLU())\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(*self.encoder)\n",
    "        self.decoder = torch.nn.Sequential(*self.decoder)\n",
    "            \n",
    " \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ae(node_type, ae_hidden_dims, epochs=30):\n",
    "    sparse_threshold = 10\n",
    "    not_sparse = torch.sum(data[node_type].x, 1).to(torch.int) > sparse_threshold\n",
    "\n",
    "    base_data = data[node_type].x[not_sparse]\n",
    "    half_data = torch.where(torch.rand_like(base_data) < 0.5, torch.zeros_like(base_data), base_data)\n",
    "\n",
    "    loader = DataLoader(\n",
    "        TensorDataset(base_data, half_data), \n",
    "        batch_size=64, shuffle=True, pin_memory=True)\n",
    "\n",
    "    ae = AE(base_data.shape[-1], ae_hidden_dims)\n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(ae.parameters(),\n",
    "                                lr = 1e-1,\n",
    "                                weight_decay = 1e-8)\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    average_losses, average_accuracies = [], []\n",
    "    for epoch in trange(epochs):\n",
    "        epoch_losses, epoch_accuracies = [], []\n",
    "        for base, half in loader:\n",
    "            reconstructed = ae(base)\n",
    "            maxed = torch.max(half, reconstructed)\n",
    "            loss = loss_function(maxed, base)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            accuracy = (torch.round(reconstructed) == base).float().mean()\n",
    "            epoch_accuracies.append(accuracy) \n",
    "            # Storing the losses in a list for plotting\n",
    "            epoch_losses.append(loss.item())\n",
    "\n",
    "        average_losses.append(np.mean(epoch_losses))\n",
    "        average_accuracies.append(np.mean(epoch_accuracies))\n",
    "        outputs.append((epochs, base, reconstructed))\n",
    "    return ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 16.67it/s]\n",
      "100%|██████████| 30/30 [00:05<00:00,  5.95it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "author_ae_dims = [128, 64, 36, 18]\n",
    "paper_ae_dims = [512,128,64,32]\n",
    "author_ae = train_ae('author', ae_hidden_dims = author_ae_dims)\n",
    "paper_ae = train_ae('paper', ae_hidden_dims = paper_ae_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AE GNN Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train(data, model, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out, filtered = model(data.x_dict, data.edge_index_dict)\n",
    "    mask = data['author'].train_mask\n",
    "    loss = F.cross_entropy(out[mask], data['author'].y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data, model):\n",
    "    model.eval()\n",
    "    pred, filtered = model(data.x_dict, data.edge_index_dict)\n",
    "    pred = pred.argmax(dim=-1)\n",
    "\n",
    "    accs = []\n",
    "    for split in ['train_mask', 'val_mask', 'test_mask']:\n",
    "        mask = data['author'][split]\n",
    "        acc = (pred[mask] == data['author'].y[mask]).sum() / mask.sum()\n",
    "        accs.append(float(acc))\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AEGNN(torch.nn.Module):\n",
    "    def __init__(self, ae, gnn):\n",
    "        super().__init__()\n",
    "        self.autoencoders = ae\n",
    "        self.gnn = gnn\n",
    " \n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for node_type, autoencoder in self.autoencoders.items():\n",
    "            filtered = autoencoder(x_dict[node_type])\n",
    "            x_dict[node_type] = filtered\n",
    "        return self.gnn(x_dict, edge_index_dict), filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode-Decode-GNN Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End 2 End, Train: 0.6900, Val: 0.5725, Test: 0.6334\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "dataset_copy = dataset.copy()\n",
    "data_copy = dataset_copy[0]\n",
    "data_copy = remove_features(data_copy, 0.5)\n",
    "\n",
    "gnn = HeteroGNN(data_copy.metadata(), hidden_channels=10, out_channels=4, num_layers=2, target_node_type='author')\n",
    "gnn = gnn.to(device)\n",
    "\n",
    "autoencoders = dict()\n",
    "autoencoders['author'] = AE(data_copy['author'].x.shape[-1], author_ae_dims).to(device)\n",
    "autoencoders['author'].load_state_dict(author_ae.state_dict())\n",
    "autoencoders['paper'] = AE(data_copy['paper'].x.shape[-1], paper_ae_dims).to(device)\n",
    "autoencoders['paper'].load_state_dict(paper_ae.state_dict())\n",
    "\n",
    "model = AEGNN(autoencoders, gnn)\n",
    "data_copy, model = data_copy.to(device), model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():  # Initialize lazy modules.\n",
    "    out = model(data_copy.x_dict, data_copy.edge_index_dict)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "\n",
    "train_accs, val_accs, test_accs = [],[],[]\n",
    "for epoch in range(1, 100):\n",
    "    loss = train(data=data_copy, model=model, optimizer=optimizer)\n",
    "    train_acc, val_acc, test_acc = test(data = data_copy, model=model)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    test_accs.append(test_acc)\n",
    "best_epoch = max(enumerate(val_accs),key=lambda x: x[1])[0]\n",
    "train_acc, val_acc, test_acc = train_accs[best_epoch], val_accs[best_epoch], test_accs[best_epoch]\n",
    "print(f'End 2 End, Train: {train_acc:.4f}, '\n",
    "        f'Val: {val_acc:.4f}, Test: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
